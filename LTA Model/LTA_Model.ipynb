{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOJ729hz+8cNFFiflolfr/N"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"B-3tuArxLmas"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","from sklearn.feature_selection import SelectKBest, f_classif\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from sklearn.metrics import confusion_matrix\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC\n","from sklearn.model_selection import cross_val_score\n","\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","import os\n","for dirname, _, filenames in os.walk('/content/drive'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))"]},{"cell_type":"code","source":["df = pd.read_csv('5_gram.csv')"],"metadata":{"id":"DxfDUDimLx2b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.head()"],"metadata":{"id":"6dhOIrv-MNRB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.shape"],"metadata":{"id":"5LzX1ffwMQJz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.isnull().sum()"],"metadata":{"id":"7n5QsbBxMReR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","# 计算Class列的值的计数\n","class_counts = df['Class'].value_counts()\n","\n","# 创建柱状图\n","plt.bar(class_counts.index.astype(str), class_counts)\n","\n","# 在柱形上方显示数量\n","for i in range(len(class_counts)):\n","    plt.text(i, class_counts[i], str(class_counts[i]), ha='center', va='bottom')\n","\n","plt.xlabel('Malware')\n","plt.ylabel('Counts')\n","plt.title('Malware Distribution in Dataset')\n","plt.show()"],"metadata":{"id":"qKNT7FXhMWuu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 分割数据为特征和目标\n","X = df.drop(columns=['Class'])  # 特征\n","y = df['Class']  # 目标\n","\n","# 分割数据为训练集和测试集\n","X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)"],"metadata":{"id":"U04-j0TBMXkO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random\n","from deap import base, creator, tools, algorithms\n","from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import train_test_split\n","\n","# 创建一个适应度函数，用于评估个体的好坏（适应度越高越好）\n","def fitness(individual):\n","    # individual 是一个二进制向量，表示特征的选择（1表示选择，0表示不选择）\n","    selected_features = [X.columns[i] for i in range(len(individual)) if individual[i] == 1]\n","\n","    # 创建一个SVM分类器\n","    classifier = SVC(kernel='linear', random_state=42)\n","\n","    # 使用选定的特征来训练和评估分类器\n","    X_train_selected = X_train[selected_features]\n","    X_test_selected = X_test[selected_features]\n","    classifier.fit(X_train_selected, y_train)\n","    y_pred = classifier.predict(X_test_selected)\n","    accuracy = accuracy_score(y_test, y_pred)\n","\n","    # 返回准确率作为适应度分数\n","    return accuracy,\n","\n","# 创建遗传算法的问题（最大化准确率）\n","creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n","creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n","\n","# 初始化遗传算法工具箱\n","toolbox = base.Toolbox()\n","\n","# 创建二进制个体，每个特征对应一个二进制位\n","toolbox.register(\"attr_bool\", random.randint, 0, 1)\n","toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, len(X.columns))\n","toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n","\n","# 定义遗传算法的操作（选择、交叉、变异）\n","toolbox.register(\"evaluate\", fitness)\n","toolbox.register(\"mate\", tools.cxTwoPoint)\n","toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.1)\n","toolbox.register(\"select\", tools.selTournament, tournsize=3)\n","\n","# 创建初始种群\n","population = toolbox.population(n=100)\n","\n","# 运行遗传算法\n","NGEN = 20  # 设置迭代次数\n","best_accuracies = []  # 用于存储每次迭代的最佳准确率\n","\n","for gen in range(NGEN):\n","    offspring = algorithms.varAnd(population, toolbox, cxpb=0.5, mutpb=0.2)\n","    fits = toolbox.map(toolbox.evaluate, offspring)\n","    for fit, ind in zip(fits, offspring):\n","        ind.fitness.values = fit\n","    population = toolbox.select(offspring, k=len(population))\n","\n","    # 获取每次迭代的最佳适应度值（准确率）\n","    best_ind = tools.selBest(population, k=1)[0]\n","    best_accuracy = best_ind.fitness.values[0]\n","    best_accuracies.append(best_accuracy)\n","\n","    print(f\"Generation {gen + 1}: Best Accuracy = {best_accuracy:.5f}\")\n","\n","# 获取最佳个体\n","best_individual = tools.selBest(population, k=1)[0]\n","selected_feature_indices = [X.columns[i] for i in range(len(best_individual)) if best_individual[i] == 1]\n","print(\"Selected Features:\", selected_feature_indices)\n","\n","# 打印每次迭代的最佳适应度值（准确率）\n","print(\"Best Accuracies Over Generations:\")\n","for gen, accuracy in enumerate(best_accuracies):\n","    print(f\"Generation {gen + 1}: {accuracy:.5f}\")\n"],"metadata":{"id":"4EoV7J7fMZaa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 画出折线图\n","import matplotlib.pyplot as plt\n","\n","# 绘制折线图\n","plt.plot(range(1, NGEN + 1), best_accuracies)\n","plt.xlabel(\"Generation\")\n","plt.ylabel(\"Best Accuracy\")\n","plt.title(\"Best Accuracy Over Generations\")\n","# plt.show()\n","\n","# 设置纵坐标的最小值\n","plt.ylim(0.9,1)\n","\n","plt.show()"],"metadata":{"id":"Gfa_l3CtMlty"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 从训练和测试数据中仅选择这些特征\n","X_train = X_train[selected_feature_indices]\n","X_test = X_test[selected_feature_indices]"],"metadata":{"id":"qgQWTTsCMoXN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train.shape"],"metadata":{"id":"Msp7CajiMq2W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","from keras.layers import LSTM, Input, Dense, MultiHeadAttention, Flatten, concatenate\n","from keras.models import Model\n","from keras.regularizers import l2, l1\n","from keras.layers import Dropout\n","from keras.callbacks import EarlyStopping\n","from tcn import TCN\n","\n","X_train_encoded_seq = X_train.to_numpy().reshape(X_train.shape[0], 1, X_train.shape[1])\n","X_test_encoded_seq = X_test.to_numpy().reshape(X_test.shape[0], 1, X_test.shape[1])\n","\n","early_stopping = EarlyStopping(\n","    monitor='val_loss',  # 监测验证集损失\n","    patience=10,         # 如果连续10个epoch验证集损失没有改善，则停止训练\n","    restore_best_weights=True  # 恢复最佳模型权重\n",")\n","\n","# LSTM\n","lstm_input = Input(shape=(1, X_train_encoded_seq.shape[2]))\n","lstm_layer = LSTM(64, return_sequences=True)(lstm_input)\n","lstm_layer = Dropout(0.5)(lstm_layer)\n","\n","# TCN\n","tcn_input = Input(shape=(1, X_train_encoded_seq.shape[2]))\n","tcn_layer = TCN(return_sequences=True)(tcn_input)\n","tcn_layer = Dropout(0.5)(tcn_layer)\n","\n","# Attention\n","attention = MultiHeadAttention(num_heads=2, key_dim=64)(query=lstm_layer, key=tcn_layer, value=tcn_layer)\n","\n","merged = concatenate([lstm_layer, tcn_layer, attention], axis=-1)\n","\n","merged = Flatten()(merged)\n","\n","output_layer = Dense(1, activation='sigmoid')(merged)\n","\n","combined_model = Model(inputs=[lstm_input, tcn_input], outputs=output_layer)\n","\n","combined_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","combined_model.fit([X_train_encoded_seq, X_train_encoded_seq], y_train, epochs=100, batch_size=64, validation_data=([X_test_encoded_seq, X_test_encoded_seq], y_test), callbacks=[early_stopping])\n","\n","# Predict labels on the test set\n","y_pred_prob = combined_model.predict([X_test_encoded_seq, X_test_encoded_seq])\n","\n","# Convert probabilities to binary labels using a threshold (0.5)\n","y_pred = (y_pred_prob > 0.5).astype(int)\n","y_pred = pd.Series(y_pred.squeeze(), index=y_test.index)\n","\n","\n","# Calculate LSTM_TCN_attention metrics\n","LSTM_TCN_attention_accuracy = accuracy_score(y_test, y_pred)\n","LSTM_TCN_attention_precision = precision_score(y_test, y_pred,average='weighted')\n","LSTM_TCN_attention_recall = recall_score(y_test, y_pred,average='weighted')\n","LSTM_TCN_attention_f1 = f1_score(y_test, y_pred,average='weighted')\n","\n","print(f\"LSTM_TCN_attention Accuracy: {LSTM_TCN_attention_accuracy:.4f}\")\n","print(f\"LSTM_TCN_attention Precision: {LSTM_TCN_attention_precision:.4f}\")\n","print(f\"LSTM_TCN_attention Recall: {LSTM_TCN_attention_recall:.4f}\")\n","print(f\"LSTM_TCN_attention F1-Score: {LSTM_TCN_attention_f1:.4f}\")\n","conf = confusion_matrix(y_pred, y_test)\n","sns.heatmap(conf , cmap='YlGnBu', fmt='', xticklabels=['0' ,'1'], yticklabels=['0' ,'1'], annot=True)\n"],"metadata":{"id":"QdgRmCpeMsHD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import shap\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","\n","from tqdm import tqdm\n","sns.set_style('whitegrid')\n","import matplotlib.pyplot as plt\n","\n","from lightgbm import LGBMClassifier\n","from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import mean_squared_error\n","from keras.callbacks import EarlyStopping\n","\n","early_stopping = EarlyStopping(\n","    monitor='val_loss',  # 监测验证集损失\n","    patience=10,         # 如果连续10个epoch验证集损失没有改善，则停止训练\n","    restore_best_weights=True  # 恢复最佳模型权重\n",")\n","\n","lencoder = LabelEncoder()\n","\n","params = {\n","       'objective': 'binary',\n","       'num_class' : 1,\n","       'metric': 'binary_logloss'\n","   }\n","\n","test_preds = None\n","train_rmse = 0\n","val_rmse = 0\n","n_splits = 10\n","\n","\n","model = LGBMClassifier(**params)\n","\n","skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n","\n","for tr_index, val_index in tqdm(skf.split(X_train.values, y_train.values), total=skf.get_n_splits(), desc=\"k-fold\"):\n","\n","    x_train_o, x_val_o = X_train.iloc[tr_index], X_train.iloc[val_index]\n","    y_train_o, y_val_o = y_train.iloc[tr_index], y_train.iloc[val_index]\n","\n","    eval_set = [(x_val_o, y_val_o)]\n","\n","    model.fit(x_train_o, y_train_o, eval_set=eval_set)\n","\n","    train_preds = model.predict(x_train_o)\n","    train_rmse += mean_squared_error(y_train_o, train_preds, squared=False)\n","\n","    val_preds = model.predict(x_val_o)\n","    val_rmse += mean_squared_error(y_val_o, val_preds, squared=False)\n","    if test_preds is None:\n","        test_preds = model.predict_proba(X_test.values)[:, 1]\n","    else:\n","        test_preds += model.predict_proba(X_test.values)[:, 1]\n","\n","print(f\"\\nAverage Training RMSE : {train_rmse / n_splits}\")\n","print(f\"Average Validation RMSE : {val_rmse / n_splits}\\n\")\n","\n","test_preds /= n_splits\n"],"metadata":{"id":"TPeRH_bqM6T8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["explainer = shap.TreeExplainer(model)\n","shap_values = explainer.shap_values(X_test)\n"],"metadata":{"id":"AQF7PvZnM-Zb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["shap.summary_plot(shap_values, X_test)"],"metadata":{"id":"Ln_RvHS4NCBP"},"execution_count":null,"outputs":[]}]}